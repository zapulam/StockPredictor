{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "lookback = 5\n",
    "\n",
    "data = pd.read_csv('monthly_prices/AAPL.csv', index_col=0)\n",
    "data.head()\n",
    "\n",
    "data_split = np.array_split(data, lookback)\n",
    "df = data_split[0]\n",
    "len(data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zpulliam\\AppData\\Local\\Temp\\ipykernel_16388\\2581330153.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  price['Close'] = scaler.fit_transform(price['Close'].values.reshape(-1,1))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.964926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.926232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.963659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.972780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.894560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Close\n",
       "0 -0.964926\n",
       "1 -0.926232\n",
       "2 -0.963659\n",
       "3 -0.972780\n",
       "4 -0.894560"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = pd.read_csv('monthly_prices/AAPL.csv', index_col=0)\n",
    "\n",
    "price = data[['Close']]\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "price['Close'] = scaler.fit_transform(price['Close'].values.reshape(-1,1))\n",
    "price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zpulliam\\Anaconda3\\envs\\ds\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tst import TimeSeriesTransformer\n",
    "\n",
    "## Model parameters\n",
    "dim_val = 512 # This can be any value divisible by n_heads. 512 is used in the original transformer paper.\n",
    "n_heads = 8 # The number of attention heads (aka parallel attention layers). dim_val must be divisible by this number\n",
    "n_decoder_layers = 4 # Number of times the decoder layer is stacked in the decoder\n",
    "n_encoder_layers = 4 # Number of times the encoder layer is stacked in the encoder\n",
    "input_size = 1 # The number of input variables. 1 if univariate forecasting.\n",
    "dec_seq_len = 92 # length of input given to decoder. Can have any integer value.\n",
    "enc_seq_len = 153 # length of input given to encoder. Can have any integer value.\n",
    "output_sequence_length = 58 # Length of the target sequence, i.e. how many time steps should your forecast cover\n",
    "max_seq_len = enc_seq_len # What's the longest sequence the model will encounter? Used to make the positional encoder\n",
    "\n",
    "model = TimeSeriesTransformer(\n",
    "    dim_val=dim_val,\n",
    "    batch_first=True,\n",
    "    input_size=input_size, \n",
    "    dec_seq_len=dec_seq_len,\n",
    "    out_seq_len=output_sequence_length, \n",
    "    n_decoder_layers=n_decoder_layers,\n",
    "    n_encoder_layers=n_encoder_layers,\n",
    "    n_heads=n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175.039993"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset import SP_500\n",
    "\n",
    "dataset = SP_500('monthly', 1)\n",
    "dataset.__getitem__(0)[3]['Open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SP_500(Dataset):\n",
    "    def __init__(self, splits):\n",
    "        self.folder = 'test'\n",
    "        self.splits = splits\n",
    "\n",
    "        self.files = os.listdir(self.folder)\n",
    "        new_files = []\n",
    "\n",
    "        max = 0\n",
    "        for file in self.files:\n",
    "            data = pd.read_csv(os.path.join(self.folder, file), index_col=0)\n",
    "            if len(data.index) > max:\n",
    "                max = len(data.index)\n",
    "\n",
    "        for file in self.files:\n",
    "            data = pd.read_csv(os.path.join(self.folder, file), index_col=0)\n",
    "            if len(data.index) == max:\n",
    "                new_files.append(file)\n",
    "\n",
    "        self.files = new_files\n",
    "        self.data = []   # stores lists of csv and partition: [AAPL.csv, n]\n",
    "\n",
    "        for file in self.files:\n",
    "            for i in range(self.splits):\n",
    "                self.data.append([file, i])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = self.data[idx][0]\n",
    "        partition = self.data[idx][1]\n",
    "\n",
    "        data = pd.read_csv(os.path.join(self.folder, file), index_col=0)\n",
    "        data_split = np.array_split(data, self.splits)\n",
    "\n",
    "        if data_split[0].shape[0] != data_split[-1].shape[0]:\n",
    "            for i, sub in enumerate(data_split):\n",
    "                if sub.shape[0] != data_split[-1].shape[0]:\n",
    "                    data_split[i] = data_split[i][0:-1]\n",
    "\n",
    "        data = data_split[partition]\n",
    "\n",
    "        x = data[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "        y = data['Close']\n",
    "\n",
    "        mins, maxs = x.min().to_numpy(), x.max().to_numpy()\n",
    "\n",
    "        x = (x-x.min())/(x.max()-x.min())\n",
    "        y = (y-y.min())/(y.max()-y.min())\n",
    "        x = x.to_numpy()\n",
    "        y = y.to_numpy()\n",
    "        y = y.reshape(-1, 1)\n",
    "\n",
    "        return x, y, mins, maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213 torch.Size([2, 100, 5]) torch.Size([2, 100, 1])\n",
      "213 torch.Size([2, 100, 5]) torch.Size([2, 100, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from rnn import LSTM, GRU\n",
    "\n",
    "model = LSTM(input_dim=5, hidden_dim=32, output_dim=1, num_layers=2)\n",
    "\n",
    "dataset = SP_500(4)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "\n",
    "lookback = 100\n",
    "\n",
    "for i, data in enumerate(dataloader):\n",
    "    #print(data[0].shape)\n",
    "\n",
    "    seqs = []\n",
    "\n",
    "    for i in range(data[0].shape[1]-1 - lookback): \n",
    "        seqs.append([data[0][:,i: i + lookback, :], data[1][:, i+1: i+1 + lookback, :]])\n",
    "\n",
    "    print(len(seqs), seqs[0][0].shape, seqs[0][1].shape) # sequences, train, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[1.4530e-01, 1.1948e-01, 2.1184e-01, 2.0224e-01, 1.8459e-01],\n",
       "          [2.1612e-01, 3.0377e-01, 3.1479e-01, 4.2985e-01, 7.4609e-01]],\n",
       " \n",
       "         [[6.0293e-04, 0.0000e+00, 0.0000e+00, 1.2620e-02, 3.6240e-01],\n",
       "          [1.9144e-02, 1.1071e-02, 3.5908e-02, 1.0000e-02, 2.0667e-01]]],\n",
       "        dtype=torch.float64),\n",
       " tensor([[[0.2022],\n",
       "          [0.4299]],\n",
       " \n",
       "         [[0.0126],\n",
       "          [0.0100]]], dtype=torch.float64)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = []\n",
    "\n",
    "x.append([data[0][:,0: 0 + 2, :], data[1][:,0: 0 + 2, :]])\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8352c3e561a2a738f2062b25c9003fdf40d787749e56eea0a1139974da14276"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
